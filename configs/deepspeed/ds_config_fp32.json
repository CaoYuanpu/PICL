{
    "train_micro_batch_size_per_gpu": 8,
    "gradient_accumulation_steps": 1,
    "zero_optimization": {
        "stage": 0
    },
    "zero_allow_untested_optimizer": true,
    "fp16": {
        "enabled": false,
        "loss_scale": 0,
        "initial_scale_power": 11,
        "loss_scale_window": 1000,
        "hysteresis": 16
    },
    "wall_clock_breakdown": false
}